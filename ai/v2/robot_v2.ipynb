{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huấn luyện mô hình với 53 mẫu, 34 đặc trưng, và 18 lớp bệnh.\n",
      "\n",
      "Xin chào! Tôi là robot trợ lý sức khỏe ảo. Hãy mô tả các triệu chứng chính bạn đang gặp phải.\n",
      "\n",
      "[Bot]: Dựa trên mô tả của bạn, tôi ghi nhận các triệu chứng sau:\n",
      "- Sốt\n",
      "- Đau đầu\n",
      "\n",
      "[Bot]: Để hiểu rõ hơn, tôi xin hỏi thêm một số câu:\n",
      "\n",
      "[Bot]: Cảm ơn bạn đã cung cấp thông tin. Đang phân tích...\n",
      "\n",
      "--- Chẩn đoán với Xác suất và Độ không chắc chắn ---\n",
      "Cúm: Xác suất = 0.067, Độ không chắc chắn (StdDev) = 0.030\n",
      "Cảm lạnh: Xác suất = 0.096, Độ không chắc chắn (StdDev) = 0.076\n",
      "COVID-19: Xác suất = 0.060, Độ không chắc chắn (StdDev) = 0.036\n",
      "Dị ứng: Xác suất = 0.059, Độ không chắc chắn (StdDev) = 0.042\n",
      "Viêm xoang: Xác suất = 0.084, Độ không chắc chắn (StdDev) = 0.066\n",
      "Đau nửa đầu Migraine: Xác suất = 0.055, Độ không chắc chắn (StdDev) = 0.040\n",
      "Căng thẳng Stress: Xác suất = 0.034, Độ không chắc chắn (StdDev) = 0.029\n",
      "Viêm họng: Xác suất = 0.055, Độ không chắc chắn (StdDev) = 0.028\n",
      "Trào ngược dạ dày thực quản: Xác suất = 0.052, Độ không chắc chắn (StdDev) = 0.035\n",
      "Viêm phế quản: Xác suất = 0.043, Độ không chắc chắn (StdDev) = 0.027\n",
      "Rối loạn lo âu lan tỏa: Xác suất = 0.033, Độ không chắc chắn (StdDev) = 0.031\n",
      "Viêm tai giữa: Xác suất = 0.047, Độ không chắc chắn (StdDev) = 0.026\n",
      "Zona thần kinh: Xác suất = 0.031, Độ không chắc chắn (StdDev) = 0.020\n",
      "Hen suyễn: Xác suất = 0.048, Độ không chắc chắn (StdDev) = 0.028\n",
      "Tiểu đường type 2: Xác suất = 0.082, Độ không chắc chắn (StdDev) = 0.061\n",
      "Thiếu máu do thiếu sắt: Xác suất = 0.032, Độ không chắc chắn (StdDev) = 0.028\n",
      "Viêm da cơ địa: Xác suất = 0.046, Độ không chắc chắn (StdDev) = 0.033\n",
      "Mất nước: Xác suất = 0.075, Độ không chắc chắn (StdDev) = 0.068\n",
      "\n",
      "Chẩn đoán sơ bộ: Cảm lạnh (Độ không chắc chắn cho chẩn đoán này: ±0.076)\n",
      "\n",
      "Lưu ý: Đây chỉ là chẩn đoán sơ bộ dựa trên mô hình AI. Bạn nên tham khảo ý kiến của bác sĩ để có chẩn đoán chính xác và kế hoạch điều trị phù hợp.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import pyttsx3 # Bỏ qua TTS theo yêu cầu trước\n",
    "import re\n",
    "import pandas as pd # Thư viện để làm việc với CSV\n",
    "from collections import deque # Dùng cho hàng đợi câu hỏi\n",
    "\n",
    "# --- Hằng số và Cấu hình ---\n",
    "DISEASES_CSV = 'diseases.csv'\n",
    "SYMPTOMS_CSV = 'symptoms.csv'\n",
    "DISEASE_SYMPTOMS_MATRIX_CSV = 'disease_symptoms_matrix.csv'\n",
    "\n",
    "# --- Tải và Chuẩn bị Dữ liệu ---\n",
    "def load_data():\n",
    "    diseases_df = pd.read_csv(DISEASES_CSV)\n",
    "    symptoms_df = pd.read_csv(SYMPTOMS_CSV)\n",
    "    matrix_df = pd.read_csv(DISEASE_SYMPTOMS_MATRIX_CSV)\n",
    "\n",
    "    TEN_BENH_LIST = diseases_df['TenBenh'].tolist()\n",
    "    \n",
    "    # Lấy danh sách các triệu chứng chính (sẽ là feature cho model)\n",
    "    TRIEU_CHUNG_CHINH_DF = symptoms_df[symptoms_df['LaTrieuChungChinh'] == True]\n",
    "    MA_TRIEU_CHUNG_CHINH_LIST = TRIEU_CHUNG_CHINH_DF['MaTrieuChung'].tolist()\n",
    "    TEN_TRIEU_CHUNG_CHINH_LIST = TRIEU_CHUNG_CHINH_DF['TenTrieuChung'].tolist() # Tên để hiển thị\n",
    "\n",
    "    # Tạo X_train và y_train từ matrix_df\n",
    "    # Đảm bảo các cột triệu chứng trong matrix_df khớp và đúng thứ tự với MA_TRIEU_CHUNG_CHINH_LIST\n",
    "    # Nếu matrix_df có các cột không phải là mã triệu chứng (ví dụ: TenBenh), chúng ta cần loại bỏ\n",
    "    feature_columns = [col for col in matrix_df.columns if col in MA_TRIEU_CHUNG_CHINH_LIST]\n",
    "    \n",
    "    # Sắp xếp lại các cột trong matrix_df theo đúng thứ tự của MA_TRIEU_CHUNG_CHINH_LIST nếu cần\n",
    "    # Điều này quan trọng để đảm bảo tính nhất quán\n",
    "    X_train_df = matrix_df[MA_TRIEU_CHUNG_CHINH_LIST] \n",
    "    X_train = X_train_df.values.astype(np.float32)\n",
    "\n",
    "    # Chuyển đổi TenBenh thành dạng số (label encoding) rồi one-hot encoding\n",
    "    disease_to_id = {name: i for i, name in enumerate(TEN_BENH_LIST)}\n",
    "    y_labels = matrix_df['TenBenh'].map(disease_to_id).values\n",
    "    y_train = tf.keras.utils.to_categorical(y_labels, num_classes=len(TEN_BENH_LIST))\n",
    "\n",
    "    # Tạo dictionary cho từ khóa trích xuất\n",
    "    TU_KHOA_TRIEU_CHUNG_MAP = {}\n",
    "    for _, row in TRIEU_CHUNG_CHINH_DF.iterrows():\n",
    "        keywords_str = row['TuKhoaChinh']\n",
    "        if pd.notna(keywords_str): # Kiểm tra nếu không phải NaN\n",
    "            TU_KHOA_TRIEU_CHUNG_MAP[row['MaTrieuChung']] = [r'\\b' + kw.strip() + r'\\b' for kw in keywords_str.split(',')]\n",
    "        else:\n",
    "            TU_KHOA_TRIEU_CHUNG_MAP[row['MaTrieuChung']] = []\n",
    "\n",
    "\n",
    "    # Tạo dictionary các câu hỏi làm rõ\n",
    "    # Key: MaTrieuChungChinh, Value: list các MaTrieuChungCon\n",
    "    CAU_HOI_LAM_RO_MAP = {}\n",
    "    for _, row in symptoms_df[symptoms_df['LaTrieuChungChinh'] == False].iterrows():\n",
    "        parent_symptom_code = row['TrieuChungCha']\n",
    "        if pd.notna(parent_symptom_code):\n",
    "            if parent_symptom_code not in CAU_HOI_LAM_RO_MAP:\n",
    "                CAU_HOI_LAM_RO_MAP[parent_symptom_code] = []\n",
    "            CAU_HOI_LAM_RO_MAP[parent_symptom_code].append(row['MaTrieuChung'])\n",
    "            \n",
    "    # Map MaTrieuChung với CauHoi\n",
    "    MA_TO_CAUHOI_MAP = symptoms_df.set_index('MaTrieuChung')['CauHoi'].to_dict()\n",
    "    MA_TO_TEN_MAP = symptoms_df.set_index('MaTrieuChung')['TenTrieuChung'].to_dict()\n",
    "\n",
    "\n",
    "    return (X_train, y_train, TEN_BENH_LIST, MA_TRIEU_CHUNG_CHINH_LIST, TEN_TRIEU_CHUNG_CHINH_LIST,\n",
    "            symptoms_df, TU_KHOA_TRIEU_CHUNG_MAP, CAU_HOI_LAM_RO_MAP, MA_TO_CAUHOI_MAP, MA_TO_TEN_MAP)\n",
    "\n",
    "\n",
    "# --- Xây dựng và huấn luyện mô hình ---\n",
    "def build_and_train_model(X_train, y_train, num_features, num_classes):\n",
    "    inputs = tf.keras.Input(shape=(num_features,))\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(inputs) # Tăng số neuron một chút\n",
    "    x = tf.keras.layers.Dropout(0.5)(x, training=True)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x, training=True)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Kiểm tra nếu X_train và y_train không rỗng\n",
    "    if X_train.shape[0] == 0 or y_train.shape[0] == 0:\n",
    "        print(\"LỖI: Dữ liệu huấn luyện X_train hoặc y_train rỗng. Vui lòng kiểm tra file CSV.\")\n",
    "        return None\n",
    "    if X_train.shape[0] != y_train.shape[0]:\n",
    "        print(f\"LỖI: Số lượng mẫu trong X_train ({X_train.shape[0]}) và y_train ({y_train.shape[0]}) không khớp.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Huấn luyện mô hình với {X_train.shape[0]} mẫu, {X_train.shape[1]} đặc trưng, và {y_train.shape[1]} lớp bệnh.\")\n",
    "    model.fit(X_train, y_train, epochs=150, verbose=0, batch_size=min(32, X_train.shape[0])) # Thêm batch_size\n",
    "    return model\n",
    "\n",
    "# --- Chức năng Text-to-Speech (TTS) - (Có thể bật lại nếu cần) ---\n",
    "# def speak_vietnamese(text): ... (như cũ)\n",
    "\n",
    "# --- Dự đoán với độ không chắc chắn (Monte Carlo Dropout) ---\n",
    "def predict_with_uncertainty(model, x_input, n_iter=100):\n",
    "    if x_input.ndim == 1: # Nếu chỉ là 1 mẫu, reshape lại\n",
    "        x_input = np.expand_dims(x_input, axis=0)\n",
    "    preds_list = [model(x_input, training=True).numpy() for _ in range(n_iter)]\n",
    "    preds = np.array(preds_list)\n",
    "    mean_probs = preds.mean(axis=0)\n",
    "    std_devs = preds.std(axis=0)\n",
    "    return mean_probs, std_devs\n",
    "\n",
    "# --- Xử lý đầu vào ngôn ngữ tự nhiên đơn giản cho câu hỏi Có/Không ---\n",
    "def interpret_yes_no_vietnamese(answer_text):\n",
    "    answer = answer_text.strip().lower()\n",
    "    positive_responses = [\"có\", \"c\", \"yes\", \"y\", \"đúng\", \"phải\", \"roi\", \"co\", \" bị\"]\n",
    "    # Thêm một số từ phủ định cơ bản\n",
    "    negative_responses = [\"không\", \"k\", \"no\", \"n\", \"sai\", \"chưa\", \"khong\", \"ko\", \"đéo\"] \n",
    "    \n",
    "    for neg_word in negative_responses:\n",
    "        if neg_word in answer:\n",
    "            # Xử lý trường hợp \"không có\" vs \"có\"\n",
    "            is_truly_negative = True\n",
    "            for pos_word in positive_responses:\n",
    "                if pos_word in answer and answer.find(pos_word) < answer.find(neg_word): # \"có ... không\"\n",
    "                    # Đây có thể là một câu hỏi, hoặc \"có nhưng không nhiều\", cần xử lý tinh vi hơn\n",
    "                    # Tạm thời, nếu \"có\" xuất hiện trước \"không\" thì vẫn coi là có\n",
    "                    # is_truly_negative = False # Cân nhắc lại logic này\n",
    "                    pass\n",
    "            if is_truly_negative:\n",
    "                return 0 # Nếu có từ phủ định và không bị ghi đè bởi từ khẳng định đứng trước\n",
    "\n",
    "    for pos_word in positive_responses:\n",
    "        if pos_word in answer:\n",
    "            return 1\n",
    "            \n",
    "    # Nếu không rõ ràng, hỏi lại hoặc mặc định là không\n",
    "    # print(\"[Bot]: Xin lỗi, tôi chưa hiểu rõ câu trả lời của bạn. Bạn có thể nói rõ hơn là 'Có' hay 'Không' được không?\")\n",
    "    return 0 # Mặc định là không nếu không rõ\n",
    "\n",
    "# --- Trích xuất triệu chứng cơ bản từ văn bản tự do ---\n",
    "def extract_initial_symptoms_from_text(text_input, tu_khoa_map, ma_trieu_chung_chinh_list):\n",
    "    detected_symptoms_values = {ma_tc: 0 for ma_tc in ma_trieu_chung_chinh_list}\n",
    "    text_lower = text_input.lower()\n",
    "\n",
    "    for ma_tc, keyword_patterns in tu_khoa_map.items():\n",
    "        if ma_tc in detected_symptoms_values: # Chỉ xét các triệu chứng chính\n",
    "            for pattern in keyword_patterns:\n",
    "                try:\n",
    "                    if re.search(pattern, text_lower):\n",
    "                        detected_symptoms_values[ma_tc] = 1\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi regex với pattern '{pattern}': {e}\")\n",
    "                    continue\n",
    "    return detected_symptoms_values\n",
    "\n",
    "# --- Chạy Chatbot ---\n",
    "def run_intelligent_chatbot(model, TEN_BENH_LIST, MA_TRIEU_CHUNG_CHINH_LIST, TEN_TRIEU_CHUNG_CHINH_LIST,\n",
    "                            symptoms_df, tu_khoa_map, cau_hoi_lam_ro_map, ma_to_cauhoi_map, ma_to_ten_map):\n",
    "    if model is None:\n",
    "        print(\"Không thể khởi chạy chatbot vì mô hình chưa được huấn luyện.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nXin chào! Tôi là robot trợ lý sức khỏe ảo. Hãy mô tả các triệu chứng chính bạn đang gặp phải.\")\n",
    "    user_initial_description = input(\"Bạn: \")\n",
    "\n",
    "    # 1. Trích xuất triệu chứng ban đầu\n",
    "    # Đây sẽ là dictionary {MaTrieuChungChinh: 0 hoặc 1}\n",
    "    current_symptom_values_map = extract_initial_symptoms_from_text(user_initial_description, tu_khoa_map, MA_TRIEU_CHUNG_CHINH_LIST)\n",
    "    \n",
    "    print(\"\\n[Bot]: Dựa trên mô tả của bạn, tôi ghi nhận các triệu chứng sau:\")\n",
    "    has_initial_symptoms = False\n",
    "    for ma_tc, present in current_symptom_values_map.items():\n",
    "        if present:\n",
    "            print(f\"- {ma_to_ten_map.get(ma_tc, ma_tc)}\") # Lấy tên triệu chứng để hiển thị\n",
    "            has_initial_symptoms = True\n",
    "    if not has_initial_symptoms:\n",
    "        print(\"(Không phát hiện triệu chứng nào từ mô tả ban đầu)\")\n",
    "\n",
    "    # 2. Xây dựng hàng đợi câu hỏi thông minh\n",
    "    # Ưu tiên câu hỏi làm rõ cho các triệu chứng đã báo cáo, sau đó là các triệu chứng chính khác\n",
    "    question_queue = deque()\n",
    "    asked_questions = set() # Để tránh hỏi lặp lại\n",
    "\n",
    "    # Thêm câu hỏi làm rõ cho các triệu chứng đã được phát hiện\n",
    "    for ma_tc_chinh, present in current_symptom_values_map.items():\n",
    "        if present and ma_tc_chinh in cau_hoi_lam_ro_map:\n",
    "            for ma_tc_con in cau_hoi_lam_ro_map[ma_tc_chinh]:\n",
    "                if ma_tc_con not in asked_questions:\n",
    "                    question_queue.append(ma_tc_con)\n",
    "                    asked_questions.add(ma_tc_con)\n",
    "    \n",
    "    # Thêm các câu hỏi về triệu chứng chính chưa được đề cập hoặc chưa có câu trả lời\n",
    "    for i, ma_tc_chinh in enumerate(MA_TRIEU_CHUNG_CHINH_LIST):\n",
    "        if current_symptom_values_map.get(ma_tc_chinh, 0) == 0: # Nếu chưa được phát hiện hoặc chưa được hỏi\n",
    "             if ma_tc_chinh not in asked_questions:\n",
    "                question_queue.append(ma_tc_chinh) # Thêm mã triệu chứng chính vào hàng đợi\n",
    "                asked_questions.add(ma_tc_chinh)\n",
    "\n",
    "    print(\"\\n[Bot]: Để hiểu rõ hơn, tôi xin hỏi thêm một số câu:\")\n",
    "    \n",
    "    # Lưu trữ câu trả lời cho các câu hỏi làm rõ (không trực tiếp vào model features)\n",
    "    detailed_answers = {}\n",
    "\n",
    "    while question_queue:\n",
    "        ma_tc_to_ask = question_queue.popleft()\n",
    "        question_text = ma_to_cauhoi_map.get(ma_tc_to_ask, f\"Bạn có bị {ma_to_ten_map.get(ma_tc_to_ask, ma_tc_to_ask).lower()} không?\")\n",
    "        \n",
    "        # Kiểm tra nếu triệu chứng chính đã được trả lời rồi thì không hỏi lại\n",
    "        # (Ví dụ: nếu TC001_1 (con của TC001) được hỏi, và TC001 chưa được xác nhận là 1, thì vẫn hỏi TC001)\n",
    "        # Logic này cần tinh chỉnh thêm nếu các câu hỏi con phức tạp\n",
    "        \n",
    "        ans_text = input(f\"[Bot]: {question_text} \")\n",
    "        \n",
    "        # Kiểm tra xem đây là câu hỏi cho triệu chứng chính hay câu hỏi làm rõ\n",
    "        is_main_symptom_q = symptoms_df.loc[symptoms_df['MaTrieuChung'] == ma_tc_to_ask, 'LaTrieuChungChinh'].iloc[0]\n",
    "\n",
    "        if is_main_symptom_q:\n",
    "            # Đây là câu hỏi về một triệu chứng chính\n",
    "            answer_value = interpret_yes_no_vietnamese(ans_text)\n",
    "            current_symptom_values_map[ma_tc_to_ask] = answer_value\n",
    "            # Nếu người dùng trả lời \"Có\" cho một triệu chứng chính, thêm các câu hỏi con của nó vào hàng đợi (nếu có và chưa hỏi)\n",
    "            if answer_value == 1 and ma_tc_to_ask in cau_hoi_lam_ro_map:\n",
    "                for ma_tc_con in cau_hoi_lam_ro_map[ma_tc_to_ask]:\n",
    "                    if ma_tc_con not in asked_questions:\n",
    "                        question_queue.appendleft(ma_tc_con) # Ưu tiên hỏi câu hỏi con ngay\n",
    "                        asked_questions.add(ma_tc_con)\n",
    "        else:\n",
    "            # Đây là câu hỏi làm rõ, lưu câu trả lời text (có thể xử lý sau này)\n",
    "            detailed_answers[ma_tc_to_ask] = ans_text.strip()\n",
    "\n",
    "\n",
    "    print(\"\\n[Bot]: Cảm ơn bạn đã cung cấp thông tin. Đang phân tích...\")\n",
    "    \n",
    "    # Chuẩn bị input_vector cho model từ current_symptom_values_map\n",
    "    # Đảm bảo thứ tự của input_vector khớp với MA_TRIEU_CHUNG_CHINH_LIST\n",
    "    input_vector = np.array([current_symptom_values_map.get(ma_tc, 0) for ma_tc in MA_TRIEU_CHUNG_CHINH_LIST], dtype=np.float32)\n",
    "\n",
    "    # 3. Dự đoán\n",
    "    mean_probabilities, std_dev_probabilities = predict_with_uncertainty(model, input_vector)\n",
    "\n",
    "    most_likely_index = np.argmax(mean_probabilities[0])\n",
    "    diagnosis = TEN_BENH_LIST[most_likely_index]\n",
    "    \n",
    "    print(\"\\n--- Chẩn đoán với Xác suất và Độ không chắc chắn ---\")\n",
    "    for i, benh_name in enumerate(TEN_BENH_LIST):\n",
    "        print(f\"{benh_name}: Xác suất = {mean_probabilities[0][i]:.3f}, Độ không chắc chắn (StdDev) = {std_dev_probabilities[0][i]:.3f}\")\n",
    "\n",
    "    print(f\"\\nChẩn đoán sơ bộ: {diagnosis} (Độ không chắc chắn cho chẩn đoán này: ±{std_dev_probabilities[0][most_likely_index]:.3f})\")\n",
    "    \n",
    "    # (Tùy chọn) Hiển thị các khuyến nghị về xét nghiệm và thuốc (cần map từ diseases.csv)\n",
    "    # ... (Thêm logic lấy XET_NGHIEM_KHUYEN_NGHI và THUOC_KHUYEN_NGHI từ file CSV hoặc cấu trúc dữ liệu khác nếu muốn)\n",
    "\n",
    "    print(f\"\\nLưu ý: Đây chỉ là chẩn đoán sơ bộ dựa trên mô hình AI. Bạn nên tham khảo ý kiến của bác sĩ để có chẩn đoán chính xác và kế hoạch điều trị phù hợp.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Tải dữ liệu\n",
    "    (X_train, y_train, TEN_BENH_LIST, MA_TRIEU_CHUNG_CHINH_LIST, TEN_TRIEU_CHUNG_CHINH_LIST,\n",
    "     symptoms_df, tu_khoa_map, cau_hoi_lam_ro_map, ma_to_cauhoi_map, ma_to_ten_map) = load_data()\n",
    "\n",
    "    # Xây dựng và huấn luyện mô hình\n",
    "    num_features = X_train.shape[1]\n",
    "    num_classes = len(TEN_BENH_LIST)\n",
    "    model = build_and_train_model(X_train, y_train, num_features, num_classes)\n",
    "\n",
    "    # Chạy chatbot\n",
    "    if model:\n",
    "        run_intelligent_chatbot(model, TEN_BENH_LIST, MA_TRIEU_CHUNG_CHINH_LIST, TEN_TRIEU_CHUNG_CHINH_LIST,\n",
    "                                symptoms_df, tu_khoa_map, cau_hoi_lam_ro_map, ma_to_cauhoi_map, ma_to_ten_map)\n",
    "    else:\n",
    "        print(\"Kết thúc chương trình do lỗi huấn luyện mô hình.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
